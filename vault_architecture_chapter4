What is vault?
 - manage secrets and protect sensitive data
 - provides a single source of secrets for both humans and machines
 - provides complete lifecycle management for secrets which eliminates secret sprawl, securely stores secrets, provides governance for access to secrets
What is a secret?
 - anything your organization deems sensitive such as usernames/passwords, certificates, api keys, certificates, encryption keys
Deploying the consul storage backend
 - consul is deployed using multiple nodes and configured as a cluster
 - clusters are deployed in odd numbers (for voting members)
 - all data is replicated among all nodes in the cluster
 - a leader electrion promotes a single consul node as the leader
 - the leader accepts new logs entries and replicates to all other nodes
 - consult cluster for vault storage backend should'nt be used for consul functions in a production setting
Deploying the integrated storage backend
 - integrated storage (aka Raft) allows vault nods to provide its own replicated storage across the vault nodes within a cluster
 - define a local path to store replicated date
 - all data is replicated among all nodes in the cluster
 - eliminates the need to also run a consul cluster and manage it
Storage backends
 - configures location for storage of vault data
 - storage is defined in the main vault configuration file with desired parameters
 - all data is encrypted in transit TLS and at rest using aes256
 - not all storage backends are created equal (some support high availability and others have better tools for management & data protection)
 - there is only one storage backend per vault cluster
Secrets engines
 - vault components that are responsible for managing secrets for your organization
 - secrets engines can store, generate and encrypt data
 - many secrets engines connect to other services to generate dynamic credentials on-demand
 - many secrets engines can be enabled and used as needed (even multiple secrets engines of the same type)
 - secret engines are enabled and isolated at a path (all interactions are done directly with the path itself)
Auth methods
 - vault components that perform authentication and manage identities
 - responsible for assigning identity and policies to a user
 - multiple authentication methods can be enabled depending on your use case (auth methods can be differentiated by human vs system methods)
 - once authenticated, vault will issue a client token used to make all subsequent vault requests (r/w). The fundamental goal of all auth methods is to obtain a token and each token has an associated policy and a TTL
 - default authentication method for a new vault deployment is token
Audit devices
 - keeps detailed log of all requests and responses to vault
 - audit log is formatted using json
 - sensitive information is hashed before logging
 - can and should have more than one audit device enabled. Vault requires at least one audit device to write the log before completing the vault request if enabled (prioritizes safety over availability)

Vault paths 
 - everything in vault is path-based
 - the path prefix tells vault which component a request should be routed
 - secret engines, auth methods, and audit devices are mounted at a specified path. Often referred to as a mount.
 - paths available are dependent on the features enabled in vault, such as auth methods and secrets engines
 - system backend is a default backend in vault is mounted at the /sys endpoint
 - vault components can be enabled at any path you'd like using the -path flag
 - vault has a few system reserved path which you cannot use or remove. auth/ (endpoint for auth method configuration) cubbyhole (endpoint used by the cubbyhole secrets engine) identity/ (endpoint for configuring vault identity) secret/ (endpoint used by key/vault v2 secrets engine if running in dev mode) sys/ (system endpoint for configuring vault)
How does vault protect my data?
Master key - used to decrypt the encryption key
 - created during vault initialization or during a rekey operation 
 - never written to storage when using traditional unseal mechanism
 - written to core/master (storage backend) when using auto unseal
Encryption key - used to encrypt/decrypt data written to storage backend
 - encrypted by the master key
 - stored alongside the data in a keyring on the storage backend
 - can be easily rotated (manual operation)

Seal and unseal
 - vault starts in a sealed state, meaning it knows where to access the data, and how, but can't decrypt it
 - almost no operations are possible when vault is in a sealed state (only status check and unsealing are possible)
 - unsealing vault means that a node can reconstruct the master key in order to decrypt the encryption key and ultimately read the data
 - after unsealing, the necryption key is stored in memory
 - sealing vault means vault throws away the encryption key and requires another unseal to perform any further operations
 - vault will start in a sealed state - you can also manually seal it via ui, cli or api
 - when would i seal vault? key shards are inadvertently exposed, detection of a compromise or network intrusion or spyware/malware on the vault nodes
 - options - 1. key sharding (shamir) 2. cloud auto unseal 3. transit auto unseal
Unseal with key shards
 - default option for unsealing - no config needed
 - no single person should have access to all key shards
 - ideally, each key shard should be stored by a different employee
 - when initializing vault, you can request the individual shards to be encrypted with different pgp keys 
 - when unsealing vault, you will need an equal number of employees to provide their key which is equal to the threshold
 - key shards should not be stored online and should be highly protected - ideally stored encrypted
Unsealing with auto unseal 
 - auto unseal uses a cloud or on-premises HSM to decrypt the master key
 - vault configuration file identifies the particular key to use for decryption 
 - cloud auto unseal automatically unseals vault upon service or node restart without additional intervention
 - available in both open source and enterprise editions
 - formally an enterprise-only feature until vault 1.0
Unsealing with transit auto unseal
 - uses the transit secret engine of a different vault cluster
 - the transit secret engine may be configured in a namespace
 - the transit unseal supports key rotation 
 - available in open source and enterprise
 - the core vault cluster must be highly-available

Vault configuration file
-------------------
 - vault servers are configured using a file (written in hcl of json)
 - the configuration file includes different stanzas and parameters to define a variety of configuration options
 - configuration file is specified when starting vault using -config flag
 $ vault server -config <location>
 - usually stored somewhere in /etc but can be in different location cush as /etc/vault.d/vault.hcl
 $ vault server -config /etc/vault.d/vault.hcl
 - we configure in the file: storage backend, listener(s) and port, tls certificate, seal type, cluster name, log level, UI, cluster IP and Port

example configuration file:
listener "tcp" {
 address = "0.0.0.0:8200"
 cluster_address = "0.0.0.0:8201"
 tls_disable = "true"
}
seal "awskms" {
 region = "<region>"
 kms_key_id = "<kms_key>"
}
api_addr = "https://IPADDRESS:8200"
ui = true
cluster_name = "vault_cluster"

available stanzas:
 - seal - seal type
 - listener - addresses/ports for vault
 - storage - storage backend
 - telemetry - where to publish metrics to upstream systems
example of parameters:
 - cluster_name - identifier for the cluster - vault with with auto-generate name if omitted
 - log_level - specifies the log level to use - trace, debug, error, warn, info
 - ui - enables the built-in web ui
 - api_addr - address to advertise to other vault servers for cluster redirection
 - cluster_addr - address to advertise to other vault servers for request forwarding

example configuration file:
storage "consul" {
 address = "127.0.0.1:8500"
 path = "vault/"
 token = "123456789"
}
listener "tcp" {
 address = "0.0.0.0:8200"
 cluster_address = "0.0.0.0:8201"
 tls_cluster = 0
 tls_cert_file = "/etc/vault.d/client.pem"
 tls_key_file = "/etc/vault.d/cert.key"
 tls_disable_client_certs = "true"
}
seal "awskms" {
 region = "us-east-1"
 kms_key_id = "123456789"
 endpoint = "example.kms.us-east-1.vpce".amazonaws.com"
}
api_addr = "https://vault-us-east-1.example.com:8200"
cluster_addr = "https://node-a-us-east-1.example.com:8201"
cluster_name = "vault-prod-us-east-1"
ui = true
log_level = "INFO"

Storage backend
-------------------
 - configures location for storage of vault data
 - open-source users can choose a storage backend based on their preferences 
 - enterprise vault clusters should use hashicorp consul or integrated storage
 - as options we have aerospike, azure, cassandra, covkroachDB, consul, couchDB, etcd, ...
 - if we do not working in production, we can choose in-memory
 - in production, with HA support not needed and hashicorp not supported we can use Azure, cassandra, cockroachDB, couchDB, manta, mssql, s3, swift and if Hashicorp is supported we can use Filesystem
 - in production, with HA support and Hashicorp not supported, we can use DynamoDB, Etcd, FoundationDB, Google Cloud Spanner, Google Cloud Storage, MySQL, PostgreSQL, Zookeeper and if hashicorp supported, we can  use consul or raft

Audit device
------------------
 - keep a detailed log of all authenticated requests and responses to vault
 - audit log is formatted using json
 - sensitive information is hashed with a salt using hmac-sha256 to ensure secrets and tokens aren't ever in plain text
 - log files should be protected as a user with permission can still check the vault of those secrets via the /sts/audit-hash API compare to the log file
 $ vault audit enable file file_path=/var/log/vault_audit_log.log
file
 - writes to a file - appends logs to the file
 - does not assist with log rotation 
 - use fluentd or similar tool to send to collector
syslog 
 - writes audit logs to a syslog 
 - sends to a local agent only
socket 
 - writes toa  tcp, udp or unix socket
 - unreliable 
 - should be used where strong guarantees are not required
